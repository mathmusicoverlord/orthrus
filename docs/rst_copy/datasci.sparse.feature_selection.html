

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>datasci.sparse.feature_selection namespace &mdash; DataSci 1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> DataSci
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../rst/getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rst/modules.html">datasci</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">DataSci</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>datasci.sparse.feature_selection namespace</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/rst_copy/datasci.sparse.feature_selection.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="datasci-sparse-feature-selection-namespace">
<h1>datasci.sparse.feature_selection namespace<a class="headerlink" href="#datasci-sparse-feature-selection-namespace" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-datasci.sparse.feature_selection.kffs">
<span id="datasci-sparse-feature-selection-kffs-module"></span><h2>datasci.sparse.feature_selection.kffs module<a class="headerlink" href="#module-datasci.sparse.feature_selection.kffs" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="datasci.sparse.feature_selection.kffs.KFFS">
<em class="property">class </em><code class="sig-prename descclassname">datasci.sparse.feature_selection.kffs.</code><code class="sig-name descname">KFFS</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">k</span><span class="o">=</span><span class="default_value">5</span></em>, <em class="sig-param"><span class="n">n</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">classifier</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">f_weights_handle</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">f_rnk_func</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">training_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#datasci.sparse.feature_selection.kffs.KFFS" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>K-fold Feature Selection (kFFS) selects features using a classifier in a k-fold cross-validation experiment.
Specifically, the given classifier is trained on each fold, the features in each fold are ranked and sorted,
the top n features are selected from each fold, and the features across all folds are collected and ranked
by how many times a given feature was in the top n across each fold.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>k</strong> (<em>int</em>) – Indicates the number of folds to use in k-fold partition. Default is 5.</p></li>
<li><p><strong>n</strong> – (int): Indicates the rank threshold to use for each fold. KFFS grabs the top <code class="docutils literal notranslate"><span class="pre">n</span></code> features from each fold.</p></li>
<li><p><strong>classifier</strong> (<em>object</em>) – Class instance of the classifier being used, must contain a <code class="docutils literal notranslate"><span class="pre">fit</span></code> method.</p></li>
<li><p><strong>f_weights_handle</strong> (<em>str</em>) – Name of the classifier attribute containing the feature weights for a given fold.</p></li>
<li><p><strong>f_rnk_func</strong> (<em>object</em>) – Function to be applied to feature weights for feature ranking. Default is None, and the
features will be ranked in from least to greatest.</p></li>
<li><p><strong>training_ids</strong> (<em>list</em>) – Optional list of training ids, to restrict feature selection further.</p></li>
<li><p><strong>random_state</strong> (<em>int</em>) – Random state to generate k-fold partitions. Default is 0.</p></li>
</ul>
</dd>
<dt class="field-even">Variables</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>classifiers_</strong> (<em>series</em>) – Contains each classifier trained on each fold.</p></li>
<li><p><strong>ranks_</strong> (<em>ndarray</em>) – Contains the final rankings of all the features.</p></li>
<li><p><strong>results_</strong> (<em>ndarray</em>) – Contains the feature weights and ranks for each fold, and the final rankings.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="datasci.sparse.feature_selection.kffs.KFFS.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span></em><span class="sig-paren">)</span><a class="headerlink" href="#datasci.sparse.feature_selection.kffs.KFFS.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fits the kFFS model to the training data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like</em><em>, </em><em>(</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Training samples to be used for feature selection.</p></li>
<li><p><strong>y</strong> (<em>array-like</em><em>, </em><em>(</em><em>n_features</em><em>,</em><em>)</em>) – Training labels to be used for feature selection.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>inplace method. Results are stored in <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFFS.classifiers_</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFFS.ranks_</span></code>, and <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFFS.results_</span></code>.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-datasci.sparse.feature_selection.kfold_loso_ifr">
<span id="datasci-sparse-feature-selection-kfold-loso-ifr-module"></span><h2>datasci.sparse.feature_selection.kfold_loso_ifr module<a class="headerlink" href="#module-datasci.sparse.feature_selection.kfold_loso_ifr" title="Permalink to this headline">¶</a></h2>
<p>This module contains code for implementing an iterative feature removal (IFR) algorithm using leave one
subject out (LOSO) partitions.</p>
<dl class="py class">
<dt id="datasci.sparse.feature_selection.kfold_loso_ifr.KFLIFR">
<em class="property">class </em><code class="sig-prename descclassname">datasci.sparse.feature_selection.kfold_loso_ifr.</code><code class="sig-name descname">KFLIFR</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">classifier</span><span class="p">:</span> <span class="n">object</span></em>, <em class="sig-param"><span class="n">weights_handle</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">n_splits_kfold</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">random_state_kfold</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">train_test_splits</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">gamma</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">0.01</span></em>, <em class="sig-param"><span class="n">n_top_features</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">jump_ratio</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">sort_freq_classes</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">imputer</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#datasci.sparse.feature_selection.kfold_loso_ifr.KFLIFR" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>This iterative feature removal (IFR) algorithm produces ranked feature sets from a single classifier and a data set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier</strong> (<em>object</em>) – The classifier used to select features. The classifier should produce feature weights and ideally
be sparse, so that relatively few features are weighted heavily compared to the total.</p></li>
<li><p><strong>weights_handle</strong> (<em>str</em>) – The name of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFLIFR.classifier</span></code> attribute where the weights are stored. The
weights stored there should be an ndarray.</p></li>
<li><p><strong>n_splits_kfold</strong> (<em>int</em>) – The number of folds, <code class="docutils literal notranslate"><span class="pre">k</span></code> used in the k-fold cross validation.</p></li>
<li><p><strong>random_state_kfold</strong> (<em>int</em>) – The random seed used in generating the k-fold partitions. Good for reproducibility
of results. The default is None.</p></li>
<li><p><strong>train_test_splits</strong> (<em>list</em>) – An alternate list of (training, test) splits that replace the k-fold cross validation used
in the algorithm. This is useful if you have a specific set of splits you want to use. The default is None,
but if provided the arguments <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFLIFR.n_splits_kfold</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFLIFR.random_state_kfold</span></code> are
ignored.</p></li>
<li><p><strong>gamma</strong> (<em>float</em>) – The proportion of features used to break the IFR loop. The IFR loop will stop once the number of
features extracted reaches this proportion of the total features.</p></li>
<li><p><strong>n_top_features</strong> (<em>int</em>) – The number of top features to remove at each iteration of IFR. If this parameter is not
given then <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFLIFR.jump_ratio</span></code> will be used instead. The default is None.</p></li>
<li><p><strong>jump_ratio</strong> (<em>float</em>) – The weight ratio used to determine the number of top features to remove for each iteration
of IFR. For example let <span class="math notranslate nohighlight">\(r_i = w_{i}/w_{i+1}\)</span> denote the ratio of the
<span class="math notranslate nohighlight">\(i\)</span> th largest weight and <span class="math notranslate nohighlight">\(i+1\)</span> largest weight, then <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFLIFR.jump_ratio</span></code> = 2 means
that top features will be chosen until <span class="math notranslate nohighlight">\(r_i \geq 2\)</span>. If this parameter is not given then the user
must provide a constant number of features to prune at each step via the parameter <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFLIFR.n_top_features</span></code>.</p></li>
<li><p><strong>sort_freq_classes</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code> the algorithm will sort frequency classes of feature by the mean of
normalized weight across a LOSO experiment— providing a unique ranking. The default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>imputer</strong> (<em>object</em>) – Optional imputer to impute training set values with.</p></li>
</ul>
</dd>
<dt class="field-even">Variables</dt>
<dd class="field-even"><p><strong>results_</strong> (<em>DataFrame</em>) – Outputs the feature frequencies and rankings for each fold provided by the
k-fold partition defined by <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFLIFR.n_splits_kfold</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFLIFR.random_state_kfold</span></code>, or
the user defined splits defined by <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFLIFR.train_test_splits</span></code>.</p>
</dd>
</dl>
<dl class="py method">
<dt id="datasci.sparse.feature_selection.kfold_loso_ifr.KFLIFR.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">groups</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#datasci.sparse.feature_selection.kfold_loso_ifr.KFLIFR.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the feature selection algorithm and stores the results in the attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFLIFR.results_</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data array used to select features via <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFLIFR.classifier</span></code>.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>)</em>) – The labels used to select features via <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFLIFR.classifier</span></code>.</p></li>
<li><p><strong>groups</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>)</em>) – Optional set up of labels defining the groups used in a
Leave-One-Group-Out experiment. This is useful if you don’t want members of the same group in both the
training in test for a LOSO fold.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>inplace method.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-datasci.sparse.feature_selection.kfold_shuffle_ifr">
<span id="datasci-sparse-feature-selection-kfold-shuffle-ifr-module"></span><h2>datasci.sparse.feature_selection.kfold_shuffle_ifr module<a class="headerlink" href="#module-datasci.sparse.feature_selection.kfold_shuffle_ifr" title="Permalink to this headline">¶</a></h2>
<p>This module contains code for implementing an iterative feature removal (IFR) algorithm using leave one
subject out (LOSO) partitions.</p>
<dl class="py class">
<dt id="datasci.sparse.feature_selection.kfold_shuffle_ifr.KFSIFR">
<em class="property">class </em><code class="sig-prename descclassname">datasci.sparse.feature_selection.kfold_shuffle_ifr.</code><code class="sig-name descname">KFSIFR</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">classifier</span><span class="p">:</span> <span class="n">object</span></em>, <em class="sig-param"><span class="n">weights_handle</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">n_splits_kfold</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">random_state_kfold</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">train_test_splits</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">gamma</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">0.6</span></em>, <em class="sig-param"><span class="n">max_feature_threshold</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">n_splits_shuffle</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">random_state_shuffle</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">train_prop_shuffle</span><span class="o">=</span><span class="default_value">0.8</span></em>, <em class="sig-param"><span class="n">n_top_features</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">jump_ratio</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">sort_freq_classes</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">imputer</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#datasci.sparse.feature_selection.kfold_shuffle_ifr.KFSIFR" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>This iterative feature removal (IFR) algorithm produces ranked feature sets from a single classifier and a data set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier</strong> (<em>object</em>) – The classifier used to select features. The classifier should produce feature weights and ideally
be sparse, so that relatively few features are weighted heavily compared to the total.</p></li>
<li><p><strong>weights_handle</strong> (<em>str</em>) – The name of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFSIFR.classifier</span></code> attribute where the weights are stored. The
weights stored there should be an ndarray.</p></li>
<li><p><strong>n_splits_kfold</strong> (<em>int</em>) – The number of folds, <code class="docutils literal notranslate"><span class="pre">k</span></code> used in the k-fold cross validation.</p></li>
<li><p><strong>random_state_kfold</strong> (<em>int</em>) – The random seed used in generating the k-fold partitions. Good for reproducibility
of results. The default is None.</p></li>
<li><p><strong>train_test_splits</strong> (<em>list</em>) – An alternate list of (training, test) splits that replace the k-fold cross validation used
in the algorithm. This is useful if you have a specific set of splits you want to use. The default is None,
but if provided the arguments <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFSIFR.n_splits_kfold</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFSIFR.random_state_kfold</span></code> are
ignored.</p></li>
<li><p><strong>gamma</strong> (<em>float</em>) – Classification rate used to break the IFR loop. The IFR loop will stop once the number of
features extracted reaches this proportion of the total features.</p></li>
<li><p><strong>max_feature_threshold</strong> (<em>int</em>) – The maximum number of features that may be removed on an iteration of IFR.
Default is None.</p></li>
<li><p><strong>n_splits_shuffle</strong> (<em>int</em>) – The number of shuffle splits to use for the inner loop. Default is 100.</p></li>
<li><p><strong>random_state_shuffle</strong> (<em>int</em>) – Random seed for shuffle splits.</p></li>
<li><p><strong>n_top_features</strong> (<em>int</em>) – The number of top features to remove at each iteration of IFR. If this parameter is not
given then <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFSIFR.jump_ratio</span></code> will be used instead. The default is None.</p></li>
<li><p><strong>jump_ratio</strong> (<em>float</em>) – The weight ratio used to determine the number of top features to remove for each iteration
of IFR. For example let <span class="math notranslate nohighlight">\(r_i = w_{i}/w_{i+1}\)</span> denote the ratio of the
<span class="math notranslate nohighlight">\(i\)</span> th largest weight and <span class="math notranslate nohighlight">\(i+1\)</span> largest weight, then <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFSIFR.jump_ratio</span></code> = 2 means
that top features will be chosen until <span class="math notranslate nohighlight">\(r_i \geq 2\)</span>. If this parameter is not given then the user
must provide a constant number of features to prune at each step via the parameter <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFSIFR.n_top_features</span></code>.</p></li>
<li><p><strong>sort_freq_classes</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code> the algorithm will sort frequency classes of feature by the mean of
normalized weight across a LOSO experiment— providing a unique ranking. The default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>imputer</strong> (<em>object</em>) – Optional imputer to impute training set values with.</p></li>
</ul>
</dd>
<dt class="field-even">Variables</dt>
<dd class="field-even"><p><strong>results_</strong> (<em>DataFrame</em>) – Outputs the feature frequencies and rankings for each fold provided by the
k-fold partition defined by <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFSIFR.n_splits_kfold</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFSIFR.random_state_kfold</span></code>, or
the user defined splits defined by <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFSIFR.train_test_splits</span></code>.</p>
</dd>
</dl>
<dl class="py method">
<dt id="datasci.sparse.feature_selection.kfold_shuffle_ifr.KFSIFR.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">groups</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#datasci.sparse.feature_selection.kfold_shuffle_ifr.KFSIFR.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the feature selection algorithm and stores the results in the attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFSIFR.results_</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data array used to select features via <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFSIFR.classifier</span></code>.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>)</em>) – The labels used to select features via <code class="xref py py-attr docutils literal notranslate"><span class="pre">KFSIFR.classifier</span></code>.</p></li>
<li><p><strong>groups</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>)</em>) – Optional set up of labels defining the groups used in a
Leave-One-Group-Out experiment. This is useful if you don’t want members of the same group in both the
training in test for a LOSO fold.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>inplace method.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-datasci.sparse.feature_selection.sabs">
<span id="datasci-sparse-feature-selection-sabs-module"></span><h2>datasci.sparse.feature_selection.sabs module<a class="headerlink" href="#module-datasci.sparse.feature_selection.sabs" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="datasci.sparse.feature_selection.sabs.SABS">
<em class="property">class </em><code class="sig-prename descclassname">datasci.sparse.feature_selection.sabs.</code><code class="sig-name descname">SABS</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">b</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">alpha</span><span class="o">=</span><span class="default_value">0.001</span></em>, <em class="sig-param"><span class="n">iterations</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">store_updates</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">use_cuda</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">device</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#datasci.sparse.feature_selection.sabs.SABS" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<dl class="py method">
<dt id="datasci.sparse.feature_selection.sabs.SABS.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span></em><span class="sig-paren">)</span><a class="headerlink" href="#datasci.sparse.feature_selection.sabs.SABS.fit" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Eric Kehoe.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>